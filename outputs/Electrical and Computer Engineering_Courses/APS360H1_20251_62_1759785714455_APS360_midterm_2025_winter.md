## Page 1

University of Toronto
Faculty Of Applied Science & Engineering
Applied Fundamentals of Deep Learning
Date :
February 5, 2025
Duration:
120 minutes
Aids Allowed:
Closed Book & Non-Programmable Calculators
Instructors:
Kaveh Hassani & Justin Beland
Name :
LastName:
Student ID:
Email:
Do NOT turn this page until you have received the signal to start.
Do NOT write anything over the QR Codes on top of the pages.
This test consists of 5 questions on 10 pages (including this one),
printed on both sides of the paper. When you receive the signal to
start, please make sure that your copy of the test is complete, fill in
the identification section above. Answer each question directly on the
test paper, in the space provided. Make sure to answer the questions
in their designated place.
For multiple choice question, fill out the
best answer for each question on multiple-choice bubble sheet on
page 20. Do not fill out more than one answer per question.
Write up your solutions carefully! Marks cannot be awarded for solu-
tions that are not understandable by the grader, and may be deducted
if you make false assertions. If you are giving only one part of an an-
swer, indicate clearly what you are doing. Part marks might be given
for incomplete solutions.
Marking Guide
# 1:
/10
# 2:
/10
# 3:
/15
# 4:
/10
# 5:
/10
TOTAL:
/55
Page 1 of 10
Good Luck!
over. . .


## Page 2

Question 1.
[10 marks]
Fill out the best answer for each question on the multiple-choice bubble sheet on page 12. Do
not fill out more than one answer per question.
Part (a)
[1 mark]
Which of the following is not the pur-
pose of regularization techniques?
(A) Avoiding memorization
(B) Avoiding under-fitting
(C) Avoiding over-fitting
(D) Improving generalization
Part (b)
[1 mark]
Suppose
we
have
a
fully-connected
network of three layers consisting of 5,
10, and 20 neurons, respectively, and
input size of 10.
What is the total
number of weights and biases of the
network?
(A) 335
(B) 10,000
(C) 300
(D) 285
Part (c)
[1 mark]
If we use dropout with probability 0.3
during training, what should we do dur-
ing inference time?
(A) Apply dropout with probability 0.3
(B) Apply dropout with probability 0.7
(C) Multiply activations by 0.3
(D) Multiply activations by 0.7
Part (d)
[1 mark]
Which of the following statements is in-
correct?
(A) Weight and Biases are optimized based on
training data.
(B) Hyper-parameters are optimized based on
validation data.
(C) Data should be split by stratified sampling
with replacement.
(D) We can use accuracy to measure the perfor-
mance on balanced data.
Part (e)
[1 mark]
Which of the following is incorrent?
(A) More data can reduce over-fitting.
(B) Making a model bigger can reduce under-
fitting.
(C) Restricting the magnitude of weights can re-
duce under-fitting.
(D) Having larger weight decay can cause under-
fitting.
Page 2 of 10
cont’d. . .


## Page 3

Part (f)
[1 mark]
In CNNs, what does a filter (or kernel)
represent?
(A) A set of weights used to extract features from
an image.
(B) A mechanism for reducing the size of the in-
put.
(C) A way to normalize the input data.
(D) A fully connected layer for classification.
Part (g)
[1 mark]
Why are pooling layers used in CNNs?
(A) To increase the spatial dimensions of the in-
put.
(B) To improve the accuracy of feature extrac-
tion.
(C) To reduce the spatial dimensions and com-
putation cost.
(D) To replace convolutional layers in the net-
work.
Part (h)
[1 mark]
Which of the following is an advan-
tage of using CNNs for image processing
tasks?
(A) They are robust to changes in input size.
(B) They can learn spatial hierarchies of features
automatically.
(C) They require fewer computational resources
than traditional neural networks.
(D) All of the above.
Part (i)
[1 mark]
What does the term “stride” refer to in
the context of CNNs?
(A) The number of filters applied to an input.
(B) The distance the filter moves during convo-
lution.
(C) The size of the input image.
(D) The method used to normalize the data.
Part (j)
[1 mark]
What does the term “channel” refer to
in the context of CNNs?
(A) The spatial dimensions of the input image
(B) The width of the convolutional filter
(C) The number of pooling operations in a layer
(D) The depth of the input, such as RGB layers
in an image
Page 3 of 10
over. . .


## Page 4

Question 2.
[10 marks]
Part (a)
[5 marks]
Suppose a network is used to predict if a patient has cancer. What performance measure should we
target to optimize and how can we achieve this? What if the network is used to detect whether a
person has security clearance to enter a building? Should we change the loss computation for each
case?
Part (b)
[5 marks]
What is a possible cause for each of the following cases?
• Training loss does not decrease as the training progresses.
• Training loss increases as the training progresses.
• Training loss decreases slowly while oscillating a lot.
• Training loss decreases while validation loss increases.
• Model pays more attention to features that should not be more important than others.
Page 4 of 10
cont’d. . .


## Page 5

Question 3.
[15 marks]
Part (a)
[7 marks]
Suppose we have the following fully-connected network where the activation of the first layer is
ReLU and the output is just a linear layer. Also assume we apply a deterministic dropout where
weights of each neuron with even indices are set to zero. Suppose we feed the network with a batch
of three samples as shown. Compute the output batch using matrix notation. Show all the steps.
+1
-1
+1
+1
+1
-1
-1
+1
-1
-1
X1
X2
-1
-1
-1
-1
+1
+1
+1
+1
X3
-1
-1
+1
+1
0
Y
-1
+1
Page 5 of 10
over. . .


## Page 6

Part (b)
[8 marks]
Suppose we use a mean-square-error loss with weigh decay. Calculate the gradient with respect to
the first weight of the first neuron in the first layer. Show your steps.
Page 6 of 10
cont’d. . .


## Page 7

Question 4.
[10 marks]
A convolutional neural network has an intermediate layer that takes in an input with 8 channels
(feature maps). This layer applies 16 filters (each of size 3×3) with a stride of 1 and no padding.
Answer the following questions based on this setup. The following equation may be useful:
o =
i + 2p −k
s

+ 1
where i denotes the size of the input, p denotes the padding size, k denotes the kernel size and s
denotes the stride.
Part (a)
[2 marks]
How many channels will the output of this layer have? Explain your answer.
Part (b)
[2 marks]
Assuming the input to this layer has spatial dimensions of 32×32, what will be the spatial dimensions
of the output feature maps?
Page 7 of 10
over. . .


## Page 8

Part (c)
[4 marks]
How many trainable parameters does this convolutional layer have? Explain your work.
Part (d)
[2 marks]
How can this convolutional layer learn during training?
Page 8 of 10
cont’d. . .


## Page 9

Question 5.
[10 marks]
Below is the PyTorch implementation of a simple CNN layer:
1 import torch
2 import torch.nn as nn
3
4 class SimpleCNN(nn.Module):
5
def __init__(self):
6
super(SimpleCNN , self).__init__ ()
7
self.conv1 = nn.Conv2d(in_channels =3, out_channels =16,
8
kernel_size =5, stride =1, padding =2)
9
10
def forward(self , x):
11
return self.conv1(x)
12
13 # Create a model and input tensor
14 model = SimpleCNN ()
15 input_tensor = torch.randn(1, 3, 32, 32)
# Batch size = 1, Channels
= 3, Height = 32, Width = 32
16 output_tensor = model(input_tensor)
Part (a)
[4 marks]
What are the dimensions of output tensor? Show your calculations.
Page 9 of 10
over. . .


## Page 10

Part (b)
[4 marks]
How many trainable parameters are there in the conv1 layer?
Part (c)
[2 marks]
What will happen if we change padding=2 to padding=0 in the Conv2d layer?
Page 10 of 10
Total Marks = 55
End of Final Exam

